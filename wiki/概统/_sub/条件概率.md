### 一、核心思想：在已知条件下更新概率


### 二、定义与公式

**1. 正式定义**

设 A 和 B 是同一个随机试验中的两个事件，且$P (B) > 0$（即事件 B 已经发生是可能的）。
在事件 B 发生的条件下，事件 A 发生的**条件概率**，记作$P (A|B)$，定义为：
$$
P (A|B) = \frac{P (A \cap B)}{P (B)}
$$

---

### 三、经典例题与应用


---

**例题 2：医疗检测（贝叶斯定理的引例）**

某种疾病在人群中的患病率为 1%。针对该疾病的检测，其准确率为 99%（即患病者检测呈阳性的概率为 99%，健康人检测呈阴性的概率也为 99%）。

问：如果一个人检测结果为阳性，他真正患病的概率是多少？

**定义事件**：
-$D$：一个人实际患病。$P (D) = 0.01$
-$T^+$：检测结果为阳性。

**已知条件概率**：
-$P (T^+|D) = 0.99$（真阳性率，灵敏度）
-$P (T^-|\text{非}D) = 0.99$→$P (T^+|\text{非}D) = 0.01$（假阳性率）

**我们需要求**：$P (D|T^+)$（在检测为阳性的条件下，真正患病的概率）

**计算**：
1.  先求检测为阳性的总概率$P (T^+)$。
    - 真阳性：$P (T^+ \cap D) = P (T^+|D) \times P (D) = 0.99 \times 0.01 = 0.0099$
    - 假阳性：$P (T^+ \cap \text{非}D) = P (T^+|\text{非}D) \times P (\text{非}D) = 0.01 \times 0.99 = 0.0099$
    - 所以，$P (T^+) = 0.0099 + 0.0099 = 0.0198$

2.  应用条件概率公式：
   $$
    P (D|T^+) = \frac{P (D \cap T^+)}{P (T^+)} = \frac{0.0099}{0.0198} = 0.5
   $$

**结论**：即使检测准确率高达 99%，一个检测结果为阳性的人，其真正患病的概率也只有**50%**！这个反直觉的结果凸显了条件概率和先验概率（患病率）的重要性。这个例子直接引出了强大的**贝叶斯定理**。

---

### 四、乘法公式

由条件概率的定义$P (A|B) = \frac{P (A \cap B)}{P (B)}$，我们可以立即得到一个极其有用的公式——**乘法公式**：

$$
P (A \cap B) = P (A|B) \cdot P (B)
$$
或者等价地：
$$
P (A \cap B) = P (B|A) \cdot P (A)
$$

**推广到多个事件**：
$$
P (A \cap B \cap C) = P (A) \cdot P (B|A) \cdot P (C|A \cap B)
$$
这个公式在计算复杂事件的概率时非常有用，尤其是涉及** sequential**（顺序）过程时。


---

### 五、独立性

**1. 定义**
如果事件 B 的发生不影响事件 A 发生的概率（反之亦然），则称事件 A 和 B **相互独立**。用公式表示为：
$$
P (A|B) = P (A)
$$
或者，更常用的是：
$$
P (A \cap B) = P (A) \cdot P (B)
$$
（当$P (A)>0, P (B)>0$时，这两个定义是等价的。）

**2. 理解**
独立性意味着两个事件之间**没有因果关系或逻辑关联**。知道其中一个发生了，并不会给我们任何关于另一个是否会发生的信息。

**注意**：**互斥**（$A \cap B = \emptyset$）和**独立**是两个完全不同的概念。事实上，如果$P (A)>0$且$P (B)>0$，那么互斥事件**一定不独立**！因为如果 A 发生，B 就一定不发生，即$P (B|A) = 0 \neq P (B)$。

---

### 六、贝叶斯定理

这是条件概率皇冠上的明珠，它描述了如何根据新的证据来更新我们对某个假设的信念。

**定理公式**：
$$
P (A|B) = \frac{P (B|A) \cdot P (A)}{P (B)}
$$
其中：
-$P (A|B)$称为**后验概率**：在得到证据 B 后，对事件 A 发生概率的更新估计。
-$P(A)$称为**先验概率**：在得到任何证据之前，对事件 A 发生概率的初始信念。
-$P(B|A)$称为**似然度**：如果 A 为真，观察到证据 B 的可能性有多大。
-$P(B)$是证据 B 发生的总概率，通常用全概率公式计算：$P (B) = P (B|A) P (A) + P (B|\text{非}A) P (\text{非}A)$。

**回顾之前的医疗检测例子**，我们实际上就是不自觉地使用了贝叶斯定理：
-$A$是$D$（患病）
-$B$是$T^+$（检测阳性）
$$
P (D|T^+) = \frac{P (T^+|D) \cdot P (D)}{P (T^+)} = \frac{0.99 \times 0.01}{0.0198} = 0.5
$$

### 总结

- **条件概率**$P (A|B)$是概率论的核心，它体现了**信息更新**的思想。
- 其定义公式$P (A|B) = \frac{P (A \cap B)}{P (B)}$是所有推导的基石。
- **乘法公式**$P (A \cap B) = P (A|B) P (B)$是计算交事件概率的强大工具。
- **独立性**$P (A \cap B) = P (A) P (B)$描述了两个事件互不影响的情形。
- **贝叶斯定理**$P (A|B) = \frac{P (B|A) P (A)}{P (B)}$提供了一个系统性的框架，用于根据新证据来修正我们的认知，在统计学、机器学习、医学、法学等领域有极其广泛的应用。